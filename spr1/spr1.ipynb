{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sprawozdanie 1\n",
    "## Dzielenie kanałów, różne systemy kolorów i możliwe ich wykorzystania, histogram - rozciąganie i wyrównanie"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wczytywanie przykładowego obrazka i przenoszenie go do skali szarości przy pomocy OpenCV."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = cv2.imread('lab2.jpg')\n",
    "\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(rgb_image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(gray_image, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(r, g, b) = cv2.split(rgb_image)\n",
    "\n",
    "gray_image_naive = r / 3 + g / 3 + b /3\n",
    "plt.imshow(gray_image_naive, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Metoda prostej średniej z jednakowymi wagami dla każdego koloru (czerwony, zielony, niebieski) daje nieco spaczoną konwersję do skali szarości, ponieważ ludzkie oko nie postrzega każdego ze składowych kolorów w takiej samej ilości. W wyniku badań ostatecznie określono, że podział udziału każdego bazwego koloru jaki ludzkie oczy są w stanie zauważyć wynosi: 30% dla czerwonego, 59% dla zielonego i 11% dla niebieskiego.\n",
    "\n",
    "### Dzielenie obrazu na kolory składowe i prezentacja każdgo jako intensywność w skali szarości."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(r, g, b) = cv2.split(rgb_image)\n",
    "\n",
    "plt.title('Czerwony')\n",
    "plt.imshow(r, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title('Zielony')\n",
    "plt.imshow(g, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title('Niebieski')\n",
    "plt.imshow(b, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Konwersja obrazu do przestrzeni HSV i prezentacja każdego kanału w skali szarości."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "(h, s, v) = cv2.split(hsv_image)\n",
    "\n",
    "plt.title('Hue')\n",
    "plt.imshow(h, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title('Saturation')\n",
    "plt.imshow(s, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title('Value')\n",
    "plt.imshow(v, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wycinanie wszystkich elementów obrazu poza żółtym samochodem przy pomocy progowania w skali HSV."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask_h = cv2.inRange(h, 20, 40)\n",
    "mask_s = cv2.inRange(s, 120, 255)\n",
    "mask_v = cv2.inRange(v, 180, 255)\n",
    "\n",
    "masked_image = cv2.bitwise_and(hsv_image, hsv_image, mask=mask_h)\n",
    "masked_image = cv2.bitwise_and(masked_image, masked_image, mask=mask_s)\n",
    "masked_image = cv2.bitwise_and(masked_image, masked_image, mask=mask_v)\n",
    "masked_image_rgb = cv2.cvtColor(masked_image, cv2.COLOR_HSV2RGB)\n",
    "plt.imshow(masked_image_rgb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Przestrzeń HSV jest wykorzystana, ponieważ pozwala przy pomocy jednego parametru - Hue - wybrać interesujący nas odcień koloru. W tym przypadku jest to okolica wartości 60 stopni, ale jako że dane w OpenCV są przechowywane w zmiennych 8-bitowych, skala parametru H jest zmniejszona do 180 stopni, więc interesująca nas wartość to okolice H ~ 30. Dodatkowo na obrazie są zastosowane progowania na pozostałych zmiennych, by jak najlepiej wydobyć żółty samochód.\n",
    "\n",
    "### Histogram obrazu."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_histogram_from_rgb_image(rgb_image):\n",
    "    (r, g, b) = cv2.split(rgb_image)\n",
    "    counts, bins = np.histogram(r, bins=256)\n",
    "    plt.scatter(bins[:-1], counts, color='r', label='r', marker='.')\n",
    "\n",
    "    counts, bins = np.histogram(g, bins=256)\n",
    "    plt.scatter(bins[:-1], counts, color='g', label='g', marker='.')\n",
    "\n",
    "    counts, bins = np.histogram(b, bins=256)\n",
    "    plt.scatter(bins[:-1], counts, color='b', label='b', marker='.')\n",
    "    plt.legend()\n",
    "\n",
    "plot_histogram_from_rgb_image(rgb_image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rozciąganie kontrastu i wyrównywanie histogramu."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def stretch_contrast_of_rgb_image(rgb_image):\n",
    "    (r, g, b) = cv2.split(rgb_image)\n",
    "    min_color = np.min(np.vstack((r, g, b)))\n",
    "    max_color = np.max(np.vstack((r, g, b)))\n",
    "\n",
    "    # have to convert to int as this operation results in floats which can be incorrectly converted (values too high)\n",
    "    stretched_r = ((r - min_color) / (max_color - min_color)) * 255\n",
    "    stretched_g = ((g - min_color) / (max_color - min_color)) * 255\n",
    "    stretched_b = ((b - min_color) / (max_color - min_color)) * 255\n",
    "\n",
    "    return cv2.merge((stretched_r.astype(np.uint8), stretched_g.astype(np.uint8), stretched_b.astype(np.uint8)))\n",
    "\n",
    "contrast_stretched_image = stretch_contrast_of_rgb_image(rgb_image)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Oryginał')\n",
    "plt.imshow(rgb_image)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Rozciągnięty kontrast')\n",
    "plt.imshow(contrast_stretched_image)\n",
    "plt.gcf().set_size_inches((20, 10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Oryginalny histogram')\n",
    "plot_histogram_from_rgb_image(rgb_image)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Histogram z rozciągniętym kontrastem')\n",
    "plot_histogram_from_rgb_image(contrast_stretched_image)\n",
    "\n",
    "plt.gcf().set_size_inches((10, 10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist_equalized_r = cv2.equalizeHist(r)\n",
    "hist_equalized_g = cv2.equalizeHist(g)\n",
    "hist_equalized_b = cv2.equalizeHist(b)\n",
    "\n",
    "hist_equalized_image_rgb = cv2.merge((hist_equalized_r, hist_equalized_g, hist_equalized_b))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Orginał')\n",
    "plt.imshow(rgb_image)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Wyrównany histogram')\n",
    "plt.imshow(hist_equalized_image_rgb)\n",
    "plt.gcf().set_size_inches((20, 10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Oryginalny histogram')\n",
    "plot_histogram_from_rgb_image(rgb_image)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Histogram z wyrównaniem')\n",
    "plot_histogram_from_rgb_image(hist_equalized_image_rgb)\n",
    "\n",
    "plt.gcf().set_size_inches((10, 10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać dla danego przykładowego obrazka rozciągnie kontrastu nic nie robi, natomiast wyrównywanie histogramu zaimplementowane w OpenCV stara się osiągnąć swój cel i jak widać \"spłaszcza\" histogram. Celem obydwu metod jest rozciągnięcie \"górek\" na histogramie i o ile dla danego obrazka rozciąganie kontrastu nie daje żadnego wyniku to wyrównywanie po przez usuwanie niektórych intensywności daje dobre wyniki. Obraz jest nieco lepszy wizualnie oraz potencjalnie lepiej przystosowany do dalszej obróbki."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Progowanie\n",
    "\n",
    "Przykładowy obrazek w skali szarości"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = cv2.imread('lab3_1.jpg')\n",
    "\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(gray_image, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Porównanie różnych prostych metod (wymagających podania jakiegoś zadanego progu) binaryzacji obrazu dostępnych w OpenCV."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "methods = [('THRESH_BINARY', cv2.THRESH_BINARY), ('THRESH_BINARY_INV', cv2.THRESH_BINARY_INV), ('THRESH_TRUNC', cv2.THRESH_TRUNC), ('THRESH_TOZERO', cv2.THRESH_TOZERO), ('THRESH_TOZERO_INV', cv2.THRESH_TOZERO_INV)]\n",
    "\n",
    "thresh_value = 127\n",
    "plt.subplot(6, 1, 1)\n",
    "plt.title('Oryginał')\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "\n",
    "for i in range(len(methods)):\n",
    "    method = methods[i][1]\n",
    "\n",
    "    _, thresh = cv2.threshold(gray_image, thresh_value, 255, method)\n",
    "    plt.subplot(6, 1, i + 2)\n",
    "    plt.title(methods[i][0])\n",
    "    plt.imshow(thresh, cmap='gray')\n",
    "\n",
    "plt.gcf().set_size_inches((50, 30))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Porównanie metod adaptacyjnego doboru progu."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neighs = [5, 21, 41, 51]\n",
    "\n",
    "def adaptive_thresh(gray_image, neighs, method, thresh_type):\n",
    "\n",
    "    for i in range(len(neighs)):\n",
    "        plt.subplot(len(neighs), 1, i + 1)\n",
    "\n",
    "        thresh = cv2.adaptiveThreshold(gray_image, 255, method[1], thresh_type, neighs[i], 2)\n",
    "        plt.title(f'{method[0]}, neigh = {neighs[i]}')\n",
    "        plt.imshow(thresh, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adaptive_thresh(gray_image, neighs, ('ADAPTIVE_THRESH_MEAN_C', cv2.ADAPTIVE_THRESH_MEAN_C), cv2.THRESH_BINARY)\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adaptive_thresh(gray_image, neighs, ('ADAPTIVE_THRESH_GAUSSIAN_C', cv2.ADAPTIVE_THRESH_GAUSSIAN_C), cv2.THRESH_BINARY)\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać rozmiar sąsiedztwa w obydwu przypadkach powoduje podobne zachowanie. Przy małym sąsiedztwie w niektórych częściach obrazu (np. niebo lub trawa) jest bardzo dużo pojedynczych pikseli szumu, ale krawędzie są dość dobrze widoczne na budynku. Zwiększenie sąsiedztwa niejako odwraca sytuację i redukuje szum, ale krawędzie zaczynają się \"zlewać\". Subiektywnie metoda oparta o rozkład Gaussa daje nieco lepsze rezultaty.\n",
    "\n",
    "### Metoda Otsu automatycznego doboru progu."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ret_otsu, thresh_otsu = cv2.threshold(gray_image, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "plt.title(f'Wartość progu Otsu = {ret_otsu}')\n",
    "plt.imshow(thresh_otsu, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counts, bins = np.histogram(gray_image, bins=256)\n",
    "plt.title('Histogram obrazu w skali szarości z naniesionym progiem Otsu')\n",
    "plt.scatter(x=bins[:-1], y=counts, color='gray', marker='.', label='Poziom intensywności')\n",
    "plt.axvline(x=ret_otsu, label=f'Próg Otsu = {ret_otsu}', color='black')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Klasteryzacja obrazu metoda KMeans dostępną w OpenCV dla różnych wartości K."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Ks = [2, 4, 8]\n",
    "\n",
    "second_image = cv2.imread('lab3_2.png')\n",
    "second_image_rgb = cv2.cvtColor(second_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "second_image_rgb_flat = second_image_rgb.reshape((-1, 3))\n",
    "second_image_rgb_flat = second_image_rgb_flat.astype(np.float32)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 1.0)\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.title('Oryginał')\n",
    "plt.imshow(second_image_rgb)\n",
    "\n",
    "for i in range(len(Ks)):\n",
    "    K = Ks[i]\n",
    "    ret, labels, centers = cv2.kmeans(second_image_rgb_flat, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    centers = centers.astype(np.uint8)\n",
    "\n",
    "    ret = centers[labels]\n",
    "    ret = ret.reshape(second_image_rgb.shape)\n",
    "    plt.subplot(4, 1, i + 2)\n",
    "    plt.title(f'Klasteryzacja KMeans z K = {K}')\n",
    "    plt.imshow(ret)\n",
    "\n",
    "plt.gcf().set_size_inches((50, 30))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Klasteryzacja obrazu ze względu na ilość środków klastrów po 3 składowych kolorach daje oczekiwanych wynik. Środki znajodowane w algorytmie odpowiadają kolorom, które często występują (dominują) w obrazie, jak np. odcienie zielonego. Kolory te odpowiadają pewnym znaczącym elementom/obiektom w obrazie. Jednym z nich jest na przykład układ dróg (kolor szary).\n",
    "\n",
    "### Implementacja algorytmu Otsu."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def my_otsu(gray_image):\n",
    "    counts, bins = np.histogram(gray_image, bins=256)\n",
    "    bins = bins[:-1]\n",
    "\n",
    "    normalized_hist = counts / counts.sum()\n",
    "\n",
    "    fn_max = -np.inf\n",
    "    ret_my_otsu = -1\n",
    "\n",
    "    for i in range(1, 255):\n",
    "        c1_bins, c2_bins = np.arange(0, i), np.arange(i + 1, 256)\n",
    "\n",
    "        o1, o2 = normalized_hist[:i].sum(), normalized_hist[i + 1:].sum()\n",
    "        u1, u2 = np.sum(c1_bins * normalized_hist[:i] / o1), np.sum(c2_bins * normalized_hist[i + 1:] / o2)\n",
    "\n",
    "        fn = o1 * o2 * (u2 - u1)**2\n",
    "\n",
    "        if fn > fn_max:\n",
    "            fn_max = fn\n",
    "            ret_my_otsu = i\n",
    "\n",
    "    return ret_my_otsu"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ret_my_otsu = my_otsu(gray_image)\n",
    "\n",
    "_, thresh = cv2.threshold(gray_image, ret_my_otsu, 255, cv2.THRESH_BINARY)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(f'Próg Otsu znaleziony własną implementacją = {ret_my_otsu}')\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(f'Próg Otsu znaleziony algorytmem w OpenCV = {ret_otsu}')\n",
    "plt.imshow(thresh_otsu, cmap='gray')\n",
    "\n",
    "plt.gcf().set_size_inches((20, 10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Próg nie różni się od bibliotecznej implementacji, ale wydajność jego znajdowania przy pomocy mojej implemtacji prawdopodobnie jest znacznie niższa niż ta dla metody bibliotecznej. Potencjalne różnice, jakie mogą się pojawić, są wynikiem błędów zaokrągleń.\n",
    "\n",
    "## Interpolacja, filtry\n",
    "\n",
    "Przykładowy obrazek."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = cv2.imread('lab3_1.jpg')\n",
    "\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(rgb_image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Porównanie metod interpolacji dostępnych w OpenCV w kontekście zmieniania rozmiaru obrazu."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inter_methods = [(cv2.INTER_NEAREST, 'INTER_NEAREST'), (cv2.INTER_LINEAR, 'INTER_LINEAR'), (cv2.INTER_AREA, 'INTER_AREA'), (cv2.INTER_CUBIC, ' INTER_CUBIC'), (cv2.INTER_LANCZOS4, 'INTER_LANCZOS4')]\n",
    "\n",
    "small_image = cv2.resize(rgb_image, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LANCZOS4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# na potrzeby dokładności pikselowej i uniknięcia potencjalnych problemów z sposobem wyświetlania obrazków w jupyterze są one zapisywane na dysku\n",
    "for i in range(len(inter_methods)):\n",
    "    method = inter_methods[i][0]\n",
    "    method_name = inter_methods[i][1]\n",
    "\n",
    "    bigger_image = cv2.resize(small_image, None, fx=1.5, fy=1.5, interpolation=method)\n",
    "    bigger_image = cv2.cvtColor(bigger_image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(f'{method_name}.png', bigger_image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Po zmniejszeniu rozmiaru przykładowego obrazu o 50% i zwiększeniu o 50%:\n",
    "NEAREST - metoda ta powoduje oczywiste artefakty w kształcie kwadratów\n",
    "LINEAR - metoda ta generuje dość oczywisty efekt rozmazania\n",
    "AREA - metoda ta również generuje arftefakty w kształcie kwadratów ale w dużo mniejszym stopniu niż metoda NEAREST\n",
    "CUBIC i LANCZOS4 - podobne rezultaty ze znacznie mniejszą liczbą artefaktów w porównaniu do pozostałych metod\n",
    "\n",
    "### Działanie filtru uśredniającego na przykładowym obrazie."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_kernels = [5, 10, 15]\n",
    "mean_filtered = []\n",
    "\n",
    "for i in range(len(mean_kernels)):\n",
    "    kernel = mean_kernels[i]\n",
    "    filtered = cv2.blur(rgb_image, (kernel, kernel))\n",
    "    mean_filtered.append(filtered)\n",
    "    plt.subplot(len(mean_kernels), 1, i + 1)\n",
    "    plt.title(f'Filtr uśredniający, jądro =  ({mean_kernels[i]}, {mean_kernels[i]})')\n",
    "    plt.imshow(filtered)\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać filtr uśredniający ma efekt rozmazujący obraz. Natomiast ma też poważną wadę, gdyż wraz z rosnącym rozmiarem jądra, coraz bardziej jest widoczny efek tzw. \"color bandingu\", który nie tylko źle wygląda, ale może prowadzić do problemów przy dalszej analizie obrazu.\n",
    "\n",
    "### Działanie filtru medianowego na przykładowym obrazie."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "median_kernels = [5, 11, 15]\n",
    "median_filtered = []\n",
    "\n",
    "for i in range(len(median_kernels)):\n",
    "    kernel = median_kernels[i]\n",
    "    filtered = cv2.medianBlur(rgb_image, kernel)\n",
    "    median_filtered.append(filtered)\n",
    "    plt.subplot(len(median_kernels), 1, i + 1)\n",
    "    plt.title(f'Filtr medianowy, jądro = ({median_kernels[i]}, {median_kernels[i]})')\n",
    "    plt.imshow(filtered)\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tak jak w przypadku filtru uśredniającego, został uzyskany efekt rozmycia obrazu. W tym przypadku wraz z rosnącym rozmiarem jądra filtru, detale obrazu zostały kompletnie stracone.\n",
    "\n",
    "### Działanie filtru gaussowskiego na przykładowym obrazie."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gauss_filtered = cv2.GaussianBlur(rgb_image, (5, 5), 0)\n",
    "\n",
    "plt.imshow(gauss_filtered)\n",
    "plt.gcf().set_size_inches((20, 10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filtr gaussowski również uzyskuje efekt rozmycia obrazu. Różnica polega na tym, że nie prowadzi on do strat widocznych w poprzednich dwóch filtrach.\n",
    "\n",
    "### Binaryzacja przykładowego obrazu po filtracji wspomnianymi filtrami i bez niej."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_filtered_gray = cv2.cvtColor(mean_filtered[0], cv2.COLOR_RGB2GRAY)\n",
    "ret_otsu, thresh_mean_filtered = cv2.threshold(mean_filtered_gray, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "median_filtered_gray = cv2.cvtColor(median_filtered[0], cv2.COLOR_RGB2GRAY)\n",
    "ret_otsu, thresh_median_filtered = cv2.threshold(median_filtered_gray, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "gauss_filtered_gray = cv2.cvtColor(gauss_filtered, cv2.COLOR_RGB2GRAY)\n",
    "ret_otsu, thresh_gauss_filtered = cv2.threshold(gauss_filtered_gray, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "gray_image = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)\n",
    "ret_otsu, thresh_gray = cv2.threshold(gray_image, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.title('Binaryzacja bez filtrowania')\n",
    "plt.imshow(thresh_gray, cmap='gray')\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.title('Binaryzacja po filtrowaniu uśredniającym')\n",
    "plt.imshow(thresh_mean_filtered, cmap='gray')\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.title('Binaryzacja po filtrowaniu medianowym')\n",
    "plt.imshow(thresh_median_filtered, cmap='gray')\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.title('Binaryzacja po filtrowaniu gaussowskim')\n",
    "plt.imshow(thresh_gauss_filtered, cmap='gray')\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać binaryzacja po filtrowaniu jest znacząco inna. Filtrowanie powoduje usunięcie niektórych detali (np. tekstu widocznego na binaryzacji bez filtra). Dodatkowo można zauważyć, że obraz filtrowany gaussowsko zachowuje najwięcej krawędzi ze wszystkich pokazanych metod filtracji wraz z potencjalnie pożądanym efektem usunięcia niektórych detali.\n",
    "\n",
    "### Filtry: krzyż Robertsa, Prewitta, Sobela."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Roberts1 = np.array([[0, 1],\n",
    "                     [-1, 0]])\n",
    "\n",
    "Roberts2 = np.array([[1, 0],\n",
    "                     [0, -1]])\n",
    "\n",
    "Prewitt1 = np.array([[1, 1, 1],\n",
    "                     [0, 0, 0],\n",
    "                     [-1, -1, -1]])\n",
    "\n",
    "Prewitt2 = np.array([[1, 0, -1],\n",
    "                     [1, 0, -1],\n",
    "                     [1, 0, -1]])\n",
    "\n",
    "Sobel1 = np.array([[1, 2, 1],\n",
    "                   [0, 0, 0],\n",
    "                   [-1, -2, -1]])\n",
    "\n",
    "Sobel2 = np.array([[1, 0, -1],\n",
    "                   [2, 0, -2],\n",
    "                   [1, 0, -1]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "roberts1_image = cv2.filter2D(rgb_image, -1, Roberts1)\n",
    "roberts2_image = cv2.filter2D(rgb_image, -1, Roberts2)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Roberts')\n",
    "plt.imshow(roberts1_image)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(roberts2_image)\n",
    "\n",
    "plt.gcf().set_size_inches(30, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prewitt1_image = cv2.filter2D(rgb_image, -1, Prewitt1)\n",
    "prewitt2_image = cv2.filter2D(rgb_image, -1, Prewitt2)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Prewitt')\n",
    "plt.imshow(prewitt1_image)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(prewitt2_image)\n",
    "\n",
    "plt.gcf().set_size_inches(30, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sobel1_image = cv2.filter2D(rgb_image, -1, Sobel1)\n",
    "sobel2_image = cv2.filter2D(rgb_image, -1, Sobel2)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Sobel')\n",
    "plt.imshow(sobel1_image)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(sobel2_image)\n",
    "\n",
    "plt.gcf().set_size_inches(30, 20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Jak widać podane przykładowe filtry Robertsa, Prewitta i Sobela różnią się między samymi sobą typem krawędzi jakie zanjdują. Czyli pierwszy podany filtr Prewitta znajduje krawędzie poziome, a drugi znajduje krawędzie pionowe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = np.abs(prewitt1_image.astype(np.int32) - sobel1_image.astype(np.int32))\n",
    "\n",
    "plt.imshow(img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dodatkowo warto zauważyć na powyższym obrazku, że dla przykładowego poziomego filtru Prewitta i poziomego filtru Sobela wynik jest bardzo zbliżony. Jak łatwo się domyślić wynika to z faktu, że różnią się one jedynie jedną wagą. Środkowy piksel jest brany z dwa razy większą wagą. Stąd też różnica między tymi wynikami jest bardzo mała."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
