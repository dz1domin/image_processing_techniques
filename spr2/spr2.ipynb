{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawozdanie 2\n",
    "\n",
    "Sprawozdanie zostało opracowane w oparciu o Python 3.7 i wersję opencv-contrib 3.4.2.17 tak, aby uniknąć konieczności ręcznej kompilacji biblioteki, by wykorzystać algorytm SURF (SIFT jest otwarcie dostępny od 2020). Dla nowszych wersji Pythona i biblioteki OpenCV mogą być konieczne lekkie zmiany w kodzie.\n",
    "\n",
    "Lista wymaganych plików w tym samym folderze co notebook:\n",
    "- lab5_1.jpg\n",
    "- lab5_2.png\n",
    "- vid1.mov\n",
    "- vid2.mov\n",
    "- haarcascade_frontalface_default.xml\n",
    "- face_example.png\n",
    "- vecteezy_portrait-of-young-beautiful-woman-with-smooth-healthy-skin__119.mov (wskazane jest miejsce gdzie należy podać własne wideo z twarzą)\n",
    "\n",
    "## Znajdowanie krawędzi, transformacja Hough dla linii i okręgów\n",
    "\n",
    "Przykładowy obrazek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:42.384440Z",
     "start_time": "2023-04-23T13:00:40.554973Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('lab5_1.jpg')\n",
    "\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.imshow(gray_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porównanie metod Laplace i metody Canny do znajdowania krawędzi oraz wpływ szumu gaussowskiego na ich działanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:43.224979Z",
     "start_time": "2023-04-23T13:00:42.389429Z"
    }
   },
   "outputs": [],
   "source": [
    "gray_image_blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "laplace_edge = cv2.Laplacian(gray_image, cv2.CV_16UC1, ksize=5)\n",
    "laplace_edge_blurred = cv2.Laplacian(gray_image_blurred, cv2.CV_16UC1, ksize=5)\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title(\"Oryginał\")\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title(\"Laplace - brak dodanego szumu w obrazie\")\n",
    "plt.imshow(laplace_edge, cmap='gray')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title(\"Laplace - dodany szum\")\n",
    "plt.imshow(laplace_edge_blurred, cmap='gray')\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:43.975970Z",
     "start_time": "2023-04-23T13:00:43.224979Z"
    }
   },
   "outputs": [],
   "source": [
    "canny_edge = cv2.Canny(gray_image, 100, 256)\n",
    "canny_edge_blurred = cv2.Canny(gray_image_blurred, 100, 256)\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title(\"Oryginał\")\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title(\"Laplace - brak dodanego szumu w obrazie\")\n",
    "plt.imshow(canny_edge, cmap='gray')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title(\"Laplace - dodany szum\")\n",
    "plt.imshow(canny_edge_blurred, cmap='gray')\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoda Laplace jest bardzo czuła na szum w obrazie, co wynika z jej sposobu działania. Jako, że metoda ta próbuje obliczyć druga pochodną w obszarze obrazu, a ta z kolei jest bardzo czuła na najmniejsze zmiany. W porównaniu metoda Canny produkuje lepszy wynik, ponieważ nie stosuje pochodnych drugiego rzędu oraz ma metody \"poprawiania\" krawędzi.\n",
    "\n",
    "W obydwu przypadkach dodanie szumu przed uruchomieniem metod powoduje usunięcie niektórych krawędzi w porównaniu z poprzednimi rezultatami, a przypadku metody Laplace niektóre krawędzie stają również pogrubione i rozmazane.\n",
    "\n",
    "### Wpływ parametrów minVal, maxVal i kSize na działanie algorytmu Canny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:44.647195Z",
     "start_time": "2023-04-23T13:00:43.978977Z"
    }
   },
   "outputs": [],
   "source": [
    "minVals = [100, 200, 230]\n",
    "maxVals = [128, 200, 256]\n",
    "kSizes = [3, 5, 7]\n",
    "\n",
    "for i in range(len(minVals)):\n",
    "    canny_edge = cv2.Canny(gray_image, threshold1=minVals[i], threshold2=256)\n",
    "\n",
    "    plt.subplot(len(minVals), 1, i + 1)\n",
    "    plt.title(f'Canny minVal = {minVals[i]}')\n",
    "    plt.imshow(canny_edge, cmap='gray')\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:45.352289Z",
     "start_time": "2023-04-23T13:00:44.653170Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(maxVals)):\n",
    "    canny_edge = cv2.Canny(gray_image, threshold1=100, threshold2=maxVals[i])\n",
    "\n",
    "    plt.subplot(len(maxVals), 1, i + 1)\n",
    "    plt.title(f'Canny maxVal = {maxVals[i]}')\n",
    "    plt.imshow(canny_edge, cmap='gray')\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:46.166542Z",
     "start_time": "2023-04-23T13:00:45.352289Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(kSizes)):\n",
    "    canny_edge = cv2.Canny(gray_image, threshold1=100, threshold2=256, apertureSize=kSizes[i])\n",
    "\n",
    "    plt.subplot(len(kSizes), 1, i + 1)\n",
    "    plt.title(f'Canny kSize = {kSizes[i]}')\n",
    "    plt.imshow(canny_edge, cmap='gray')\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wpływy parametrów:\n",
    "- minVal - wraz ze wzrostem wartości krótkie krawędzie nie są przedłużane\n",
    "- maxVal - wraz ze wzrostem wartości krótkie krawędzie są usuwane\n",
    "- kSize - wraz ze wzrostem pojawia się wiele szumu w obrazie wynikowym\n",
    "\n",
    "### Wykrywanie linii metodą transformacji Hough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:46.764165Z",
     "start_time": "2023-04-23T13:00:46.166542Z"
    }
   },
   "outputs": [],
   "source": [
    "img = gray_image.copy()\n",
    "gray_image_blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "canny_blurred_edges = cv2.Canny(gray_image_blurred,50,150,apertureSize = 3)\n",
    "lines = cv2.HoughLines(canny_blurred_edges,1,np.pi/180,200)\n",
    "\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.gcf().set_size_inches((20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wpływ progu na działanie transformacji Hough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:47.627853Z",
     "start_time": "2023-04-23T13:00:46.765165Z"
    }
   },
   "outputs": [],
   "source": [
    "hough_threshs = [100, 150, 200]\n",
    "\n",
    "for i in range(len(hough_threshs)):\n",
    "    hough_thresh = hough_threshs[i]\n",
    "    img = gray_image.copy()\n",
    "    gray_image_blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    canny_blurred_edges = cv2.Canny(gray_image_blurred,50,150,apertureSize = 3)\n",
    "    lines = cv2.HoughLines(canny_blurred_edges,1,np.pi/180,hough_thresh)\n",
    "\n",
    "    for line in lines:\n",
    "        rho, theta = line[0]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "    plt.subplot(len(hough_threshs), 1, i + 1)\n",
    "    plt.title(f'Hough z progiem = {hough_thresh}')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przewidywalnie próg w transformacji Hough wraz ze swoim wzrostem powoduje zmniejszenie ilości wykrytych linii w obrazie, jako że każda linia potrzebuje więcej \"głosów\", by zostać przyjęta.\n",
    "\n",
    "### Wykrywanie okręgów przy pomocy transformacji Hough.\n",
    "\n",
    "Przykładowy obrazek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:48.368904Z",
     "start_time": "2023-04-23T13:00:47.627853Z"
    }
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('lab5_2.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:49.551735Z",
     "start_time": "2023-04-23T13:00:48.368904Z"
    }
   },
   "outputs": [],
   "source": [
    "gimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gimg = cv2.GaussianBlur(gimg, (5, 5), 0)\n",
    "\n",
    "circles = cv2.HoughCircles(gimg,cv2.HOUGH_GRADIENT,1,100,param1=50,param2=30,minRadius=150,maxRadius=200)\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for circle in circles[0]:\n",
    "    cv2.circle(img, (circle[0], circle[1]), circle[2], (255, 0, 0), 3)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.gcf().set_size_inches((20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy relatywnie prostej modyfikacji oryginalnej metody do wykrywania linii Hough można również wykrywać okręgi na obrazie. W tej modyfikacji kształty, które są kandydatami są opisane nieco inaczej niż przypadku linii (kąt i promień od początku układy współrzędnych), ale działanie jest mimo wszystko bardzo podobne.\n",
    "\n",
    "## Transformacja Hough i wykrywanie ruchu w filmie wideo\n",
    "\n",
    "### Wykrywanie linii w przykładowym filmie przy pomocy transformacji Hough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:49.553729Z",
     "start_time": "2023-04-23T13:00:49.551735Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_video(filename, image_fun, outfile):\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    if cap.isOpened():\n",
    "\n",
    "        vwidth  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        vheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        vfps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        print(vwidth, vheight, vfps)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(outfile, fourcc, vfps, (vwidth, vheight))\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            processed_frame = image_fun(gray_frame)\n",
    "\n",
    "            processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            out.write(processed_frame)\n",
    "\n",
    "        out.release()\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:00:49.561707Z",
     "start_time": "2023-04-23T13:00:49.556717Z"
    }
   },
   "outputs": [],
   "source": [
    "def hough_lines(gray_image, kernelsize=3):\n",
    "    img = gray_image.copy()\n",
    "    gray_image_blurred = cv2.medianBlur(gray_image, kernelsize)\n",
    "    canny_blurred_edges = cv2.Canny(gray_image_blurred,50,150,apertureSize = kernelsize)\n",
    "    lines = cv2.HoughLines(canny_blurred_edges,1,np.pi/180,200)\n",
    "\n",
    "    for line in lines:\n",
    "        rho, theta = line[0]\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 10000*(-b))\n",
    "        y1 = int(y0 + 10000*(a))\n",
    "        x2 = int(x0 - 10000*(-b))\n",
    "        y2 = int(y0 - 10000*(a))\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:01:23.237328Z",
     "start_time": "2023-04-23T13:00:49.564699Z"
    }
   },
   "outputs": [],
   "source": [
    "process_video('vid1.mov', hough_lines, 'vid1_processed.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plik wejściowy do wykrywania linii - \"vid1.mov\".\n",
    "\n",
    "Plik wyjściowy z narysowanymi wykrytymi liniami - \"vid1_processed.avi\".\n",
    "\n",
    "### Wykrywanie poruszających się obiektów przy pomocy prostej różnicy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:01:23.280419Z",
     "start_time": "2023-04-23T13:01:23.245313Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_video2(filename, outfile, threshold):\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "\n",
    "    if cap.isOpened():\n",
    "\n",
    "        vwidth  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        vheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        vfps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        print(vwidth, vheight, vfps)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(outfile, fourcc, vfps, (vwidth, vheight))\n",
    "\n",
    "        first_frame = None\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if first_frame is None:\n",
    "                first_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                continue\n",
    "\n",
    "            second_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            diff_frame = cv2.subtract(first_frame, second_frame)\n",
    "            _, diff_frame = cv2.threshold(diff_frame, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            processed_frame = cv2.bitwise_and(frame, frame, mask=diff_frame)\n",
    "\n",
    "            out.write(processed_frame)\n",
    "\n",
    "            first_frame = second_frame\n",
    "\n",
    "        out.release()\n",
    "        cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:02:21.467861Z",
     "start_time": "2023-04-23T13:01:23.255281Z"
    }
   },
   "outputs": [],
   "source": [
    "process_video2('vid2.mov', 'vid2_processed.avi', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plik wejściowy do wykrywania poruszających się obiektów - \"vid2.mov\".\n",
    "\n",
    "Plik wyjściowy z poruszającymi się obiektami - \"vid2_processed.avi\".\n",
    "\n",
    "Plik wynikowy pokazuje jak w prosty sposób można próbować wykrywać poruszające się na obrazie obiekty. Metoda jest jednak podatna na małe zmiany obrazie, więc nie jest idealna.\n",
    "\n",
    "### Wyszukiwanie elementów interesujących różnymi metodami w obrazie, wykrywanie twarzy w filmie wideo przy pomocy klasyfikatora kaskadowego\n",
    "\n",
    "Przykładowy obrazek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:02:22.197827Z",
     "start_time": "2023-04-23T13:02:21.471862Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('lab5_2.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykrywanie rogów metodą Harrisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:02:26.748655Z",
     "start_time": "2023-04-23T13:02:22.202812Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "harris_thresh = 125000\n",
    "blockSize = 2\n",
    "apertureSize = 3\n",
    "k = 0.04\n",
    "\n",
    "start = time.time()\n",
    "dst = cv2.cornerHarris(gray_image.astype(np.float32), blockSize, apertureSize, k)\n",
    "end = time.time()\n",
    "\n",
    "print(f'cornerHarris() zajął {end - start} sekund')\n",
    "\n",
    "out = image.copy()\n",
    "\n",
    "for i in range(dst.shape[0]):\n",
    "    for j in range(dst.shape[1]):\n",
    "        if int(dst[i,j]) > harris_thresh:\n",
    "            cv2.circle(out, (j,i), 5, (255, 0, 255), 1)\n",
    "\n",
    "plt.imshow(out)\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wykrywanie rogów metodą Shi-Thomasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:02:29.154293Z",
     "start_time": "2023-04-23T13:02:26.748655Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "dst = cv2.goodFeaturesToTrack(gray_image, 1500, 0.01, 10)\n",
    "end = time.time()\n",
    "\n",
    "print(f'goodFeaturesToTrack() zajął {end - start} sekund')\n",
    "\n",
    "out = image.copy()\n",
    "\n",
    "for circle in dst:\n",
    "    circle = circle[0]\n",
    "    cv2.circle(out, (circle[0],circle[1]), 5, (255, 0, 255), 1)\n",
    "\n",
    "plt.imshow(out)\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoda wykrywania interesujących elementów SIFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:02:32.391633Z",
     "start_time": "2023-04-23T13:02:29.153294Z"
    }
   },
   "outputs": [],
   "source": [
    "# w nowszej wersji OpenCV - cv2.SIFT_create()\n",
    "sift = cv2.xfeatures2d.SIFT_create(nfeatures=1500)\n",
    "\n",
    "start = time.time()\n",
    "kp = sift.detect(gray_image, None)\n",
    "end = time.time()\n",
    "\n",
    "print(f'sift.detect() zajął {end - start} sekund')\n",
    "\n",
    "img = image.copy()\n",
    "\n",
    "img = cv2.drawKeypoints(img, kp, None, color=(255, 0, 255))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoda wykrywania interesujących elementów SURF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:02:35.540453Z",
     "start_time": "2023-04-23T13:02:32.384651Z"
    }
   },
   "outputs": [],
   "source": [
    "surf = cv2.xfeatures2d.SURF_create(4000)\n",
    "\n",
    "start = time.time()\n",
    "kp = surf.detect(gray_image, None)\n",
    "end = time.time()\n",
    "\n",
    "print(f'surf.detect() zajął {end - start} sekund')\n",
    "\n",
    "img = image.copy()\n",
    "\n",
    "img = cv2.drawKeypoints(img, kp, None, color=(255, 0, 255))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoda wykrywania interesujących elementów FAST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:02:37.986263Z",
     "start_time": "2023-04-23T13:02:35.539473Z"
    }
   },
   "outputs": [],
   "source": [
    "fast = cv2.FastFeatureDetector_create(threshold=30)\n",
    "\n",
    "start = time.time()\n",
    "kp = fast.detect(gray_image, None)\n",
    "end = time.time()\n",
    "\n",
    "print(f'fast.detect() zajął {end - start} sekund')\n",
    "\n",
    "img = image.copy()\n",
    "\n",
    "img = cv2.drawKeypoints(img, kp, None, color=(255, 0, 255))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoda wykrywania interesujących elementów ORB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:02:40.351877Z",
     "start_time": "2023-04-23T13:02:37.955344Z"
    }
   },
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create(nfeatures=1500, fastThreshold=30)\n",
    "\n",
    "start = time.time()\n",
    "kp = orb.detect(gray_image, None)\n",
    "end = time.time()\n",
    "\n",
    "print(f'orb.detect() zajął {end - start} sekund')\n",
    "\n",
    "img = image.copy()\n",
    "\n",
    "img = cv2.drawKeypoints(img, kp, None, color=(255, 0, 255))\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.gcf().set_size_inches((30, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porównanie metod wykrywania elementów interesujących.\n",
    "\n",
    "We wszystkich metodach tak dobrano parametry (lub explicite zadano maksymalną ilość znalezionych elementów), by ich ilość wynosiła ~1500.\n",
    "\n",
    "Metoda:\n",
    "- metoda Harrisa - działa dość szybko (ale nie dość by działać, np. w czasie rzeczywistym z 30 fps) i pozwala znaleźć dość dużą ilość rogów, ale nie wszystkie; dodatkowo wymaga podania pewnego progu przyjęcia, co może być potencjalnie problematyczne\n",
    "- metoda Shi-Thomasi - pozwala również znajdować rogi w obrazie, ponieważ od metody Harrisa różni się jedynie sposobem akceptowania punktów, działa wolniej od niej wolniej, ale wydaje się zwracać lepsze wyniki, choć czasem wpada w pułapkę artefaktów w obrazie (np. znak parkingu w okolicach zaokrąglenia litery P)\n",
    "- metoda SIFT - najwolniejsza z metod, zwraca całkiem dobre wyniki, ale jej mocne strony w tym badaniu się nie okazują, a są one takie, że dla tej metody nie trzeba ręcznie za każdym razem dostrajać parametrów, jak w przypadku metody Harrisa, kiedy pracuje się z obrazem o innym rozmiarze albo kiedy elementy interesujące są większe od okna stosowanego w metodzie Harrisa\n",
    "- metoda SURF - działa podobnie jak SIFT, ale znacznie szybciej\n",
    "- metoda FAST - najszybsza z badanych metod, znajdowane przez nią rogi najlepiej pokrywają się z oczekiwaniami, ma natomiast poważne wady - wymaga podania wartości progu oraz nie radzi sobie z rogami, które nie mieszczą się w jej \"oknie\" (okręgu)\n",
    "- metoda ORB - druga najszybsza metoda, wyniki przez nią zwracane są podobne do metody FAST, jako że korzysta ona z niej z pewnymi modyfikacjami, ale nieco gorsze\n",
    "\n",
    "Dodatkowo warto zaznaczyć, że niektóre z metod potrafią również zwrócić dodatkowe informacje na temat znalezionych punktów, a niektóre nie. Do tych, które mogą zwracać dodatkowe informacje należą - SIFT, SURF, ORB. W rozwiązaniu nie skorzystano z tych informacji, ale na potrzeby innych zastosowań mogą być one bardzo przydatne.\n",
    "\n",
    "### Wykrywanie twarzy na przykładowym filmie przy pomocy gotowego klasyfikatora kaskadowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:20:58.641773Z",
     "start_time": "2023-04-23T13:18:38.508505Z"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# przykładowe wideo pobrane za darmo ze strony\n",
    "# https://www.vecteezy.com/video/5187030-portrait-of-young-beautiful-woman-with-smooth-healthy-skin-she-gently-touches-her-face-with-her-fingers-on-white-grey-background-skincare-concept\n",
    "#####################################################################################################\n",
    "cap = cv2.VideoCapture('vecteezy_portrait-of-young-beautiful-woman-with-smooth-healthy-skin__119.mov') # <- tu należy podać plik wideo/ścieżkę do niego\n",
    "#####################################################################################################\n",
    "\n",
    "vwidth  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "vheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "max_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "vfps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "frame_processing_progress = IntProgress(min=0, max=max_frames)\n",
    "display(frame_processing_progress)\n",
    "\n",
    "\n",
    "def detect_and_display(frame):\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_classifier.detectMultiScale(frame_gray, 1.1, 4)\n",
    "    for (x,y,w,h) in faces:\n",
    "        center = (x + w//2, y + h//2)\n",
    "        frame = cv2.ellipse(frame, center, (w//2, h//2), 0, 0, 360, (255, 0, 255), 4)\n",
    "    return frame\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('face_video.avi', fourcc, vfps, (vwidth, vheight))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    new_frame = detect_and_display(frame)\n",
    "\n",
    "    out.write(new_frame)\n",
    "    frame_processing_progress.value += 1\n",
    "    frame_processing_progress.description = f'{frame_processing_progress.value} z {max_frames} ramek'\n",
    "\n",
    "# usuwanie paska postępu\n",
    "clear_output()\n",
    "\n",
    "out.release()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikator kaskadowy pozwala w prosty sposób wykryć pozycję twarzy w obrazie, ale nie jest wystarczająco szybki dla dużych obrazów. Czas przetwarzania przykładowego filmiku to ~2min (filmik trwa ~8s).\n",
    "\n",
    "Przykładowy zrzut ekranu z wideo wynikowego dla szukania twarzy w obrazie.\n",
    "\n",
    "![Przykładowy zrzut ekranu z działania znajdowania twarzy w przykładowym filmie wideo.](face_example.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
